import "dotenv/config"

import { runLLM } from "@/modules/llm-engine"
import { buildPromptContext } from "@/modules/prompt-context-builder"
import { getDomia } from "@/test-utils"

async function main() {
	const domia = getDomia({
		llmModelConfigOverrides: { useCompactPrompt: true },
	})
	const transcript = "Good morning, Domia. How are you feeling today?"
	const promptContext = buildPromptContext(domia, transcript)

	console.log("ğŸ“‹ Prompt Context:\n")
	console.log(promptContext)
	console.log("\nğŸ§  Sending prompt to LLM...")

	console.time("â±ï¸ LLM Response Time")
	const reply = await runLLM(domia, promptContext)
	console.timeEnd("â±ï¸ LLM Response Time")

	console.log("\nğŸ“ LLM Reply:\n")
	console.log(reply)
}

main().catch((err) => {
	console.error("âŒ Error during LLM test:", err)
})
